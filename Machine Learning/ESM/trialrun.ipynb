{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500888ff",
   "metadata": {},
   "source": [
    "# Function Prediction for 104M protein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a00183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from esm.models.esm3 import ESM3\n",
    "import biotite.structure as bs\n",
    "import py3Dmol\n",
    "from esm.sdk.api import ESMProtein, GenerationConfig\n",
    "from esm.sdk.experimental import ESM3GuidedDecoding, GuidedDecodingScoringFunction\n",
    "from esm.sdk.api import ESM3InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf845a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scoring function (e.g. PTM scoring function)\n",
    "class PTMScoringFunction(GuidedDecodingScoringFunction):\n",
    "    def __call__(self, protein: ESMProtein) -> float:\n",
    "        # Minimal example of a scoring function that scores proteins based on their pTM score\n",
    "        # Given that ESM3 already has a pTM prediction head, we can directly access the pTM score\n",
    "        assert protein.ptm is not None, \"Protein must have pTM scores to be scored\"\n",
    "        return float(protein.ptm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5ca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50484427f2c44029a37e303acf4d541d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token= \"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\"\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252e3952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e12482060a04a618c57338364e0dcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model: ESM3InferenceClient = \u001b[43mESM3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# or \"cpu\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m## On Forge with larger ESM3 models\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#from getpass import getpass\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#    model=\"esm3-medium-2024-08\", url=\"https://forge.evolutionaryscale.ai\", token=token\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\__init__.py:363\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    361\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model: ESM3InferenceClient = ESM3.from_pretrained().to(\"cuda\") # or \"cpu\"\n",
    "\n",
    "## On Forge with larger ESM3 models\n",
    "#from getpass import getpass\n",
    "\n",
    "#from esm.sdk import client\n",
    "\n",
    "#token = getpass(\"Token from Forge console: \")\n",
    "#model = client(\n",
    "#    model=\"esm3-medium-2024-08\", url=\"https://forge.evolutionaryscale.ai\", token=token\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_protein() -> ESMProtein:\n",
    "    protein = ProteinChain.from_rcsb(\"1utn\")\n",
    "    protein = ESMProtein.from_protein_chain(protein)\n",
    "    protein.function_annotations = [\n",
    "        # Peptidase S1A, chymotrypsin family: https://www.ebi.ac.uk/interpro/structure/PDB/1utn/\n",
    "        FunctionAnnotation(label=\"peptidase\", start=100, end=114),\n",
    "        FunctionAnnotation(label=\"chymotrypsin\", start=190, end=202),\n",
    "    ]\n",
    "    return protein\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a45f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current score: -1:   0%|          | 0/32 [01:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m starting_protein = ESMProtein(sequence=\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m * PROTEIN_LENGTH)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Call guided_generate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m generated_protein = \u001b[43mptm_guided_decoding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguided_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprotein\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstarting_protein\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_decoding_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstarting_protein\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples_per_step\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\sdk\\experimental.py:91\u001b[39m, in \u001b[36mESM3GuidedDecoding.guided_generate\u001b[39m\u001b[34m(self, protein, num_decoding_steps, num_samples_per_step, denoised_prediction_temperature, track, verbose)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples_per_step):\n\u001b[32m     87\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.randomly_unmask_positions(\n\u001b[32m     88\u001b[39m         protein_tensor, num_positions_to_unmask, track=track\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     90\u001b[39m     scores.append(\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreward_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdenoised_prediction_temperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdenoised_prediction_temperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     )\n\u001b[32m     96\u001b[39m     samples.append(sample)\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Select best scoring sample\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\sdk\\experimental.py:127\u001b[39m, in \u001b[36mESM3GuidedDecoding.reward_function\u001b[39m\u001b[34m(self, protein_tensor, denoised_prediction_temperature)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreward_function\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     protein_tensor: ESMProteinTensor,\n\u001b[32m    125\u001b[39m     denoised_prediction_temperature: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     denoised_protein = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_denoised\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprotein_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdenoised_prediction_temperature\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scoring_function(denoised_protein)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\sdk\\experimental.py:193\u001b[39m, in \u001b[36mESM3GuidedDecoding.predict_denoised\u001b[39m\u001b[34m(self, protein_tensor, temperature)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(denoised_protein_tensor_output, ESMProteinError)\n\u001b[32m    192\u001b[39m denoised_protein_tensor = denoised_protein_tensor_output.protein_tensor\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m denoised_protein = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenoised_protein_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(denoised_protein, ESMProteinError)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m denoised_protein\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\models\\esm3.py:503\u001b[39m, in \u001b[36mESM3.decode\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: ESMProteinTensor) -> ESMProtein:\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_protein_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstructure_token_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_structure_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction_token_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_function_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\utils\\decoding.py:78\u001b[39m, in \u001b[36mdecode_protein_tensor\u001b[39m\u001b[34m(input, tokenizers, structure_token_decoder, function_token_decoder)\u001b[39m\n\u001b[32m     75\u001b[39m plddt, ptm = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.structure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Note: We give priority to the structure tokens over the coordinates when decoding\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     coordinates, plddt, ptm = \u001b[43mdecode_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstructure_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstructure_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstructure_token_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstructure_tokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.coordinates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m     coordinates = \u001b[38;5;28minput\u001b[39m.coordinates[\u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m, ...]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\utils\\decoding.py:161\u001b[39m, in \u001b[36mdecode_structure\u001b[39m\u001b[34m(structure_tokens, structure_decoder, structure_tokenizer, sequence)\u001b[39m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly one structure can be decoded at a time, got structure tokens of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure_tokens.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m     )\n\u001b[32m    159\u001b[39m _bos_eos_warn(\u001b[33m\"\u001b[39m\u001b[33mStructure\u001b[39m\u001b[33m\"\u001b[39m, structure_tokens[\u001b[32m0\u001b[39m], structure_tokenizer)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m decoder_output = \u001b[43mstructure_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m bb_coords: torch.Tensor = decoder_output[\u001b[33m\"\u001b[39m\u001b[33mbb_pred\u001b[39m\u001b[33m\"\u001b[39m][\n\u001b[32m    163\u001b[39m     \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m:-\u001b[32m1\u001b[39m, ...\n\u001b[32m    164\u001b[39m ]  \u001b[38;5;66;03m# Remove BOS and EOS tokens\u001b[39;00m\n\u001b[32m    165\u001b[39m bb_coords = bb_coords.detach().cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\models\\vqvae.py:400\u001b[39m, in \u001b[36mStructureTokenDecoder.decode\u001b[39m\u001b[34m(self, structure_tokens, attention_mask, sequence_id)\u001b[39m\n\u001b[32m    398\u001b[39m x = \u001b[38;5;28mself\u001b[39m.embed(structure_tokens)\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# !!! NOTE: Attention mask is actually unused here so watch out\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m x, _, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder_stack\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchain_id\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m tensor7_affine, bb_pred = \u001b[38;5;28mself\u001b[39m.affine_output_projection(\n\u001b[32m    405\u001b[39m     x, affine=\u001b[38;5;28;01mNone\u001b[39;00m, affine_mask=torch.zeros_like(attention_mask)\n\u001b[32m    406\u001b[39m )\n\u001b[32m    408\u001b[39m pae, ptm = \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\esm\\layers\\transformer_stack.py:92\u001b[39m, in \u001b[36mTransformerStack.forward\u001b[39m\u001b[34m(self, x, sequence_id, affine, affine_mask, chain_id)\u001b[39m\n\u001b[32m     90\u001b[39m hiddens = []\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     hiddens.append(x)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm(x), x, hiddens\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ptm_guided_decoding = ESM3GuidedDecoding(\n",
    "    client=model, scoring_function=PTMScoringFunction()\n",
    ")\n",
    "# Start from a fully masked protein\n",
    "PROTEIN_LENGTH = 256\n",
    "starting_protein = ESMProtein(sequence=\"_\" * PROTEIN_LENGTH)\n",
    "\n",
    "# Call guided_generate\n",
    "generated_protein = ptm_guided_decoding.guided_generate(\n",
    "    protein=starting_protein,\n",
    "    num_decoding_steps=len(starting_protein) // 8,\n",
    "    num_samples_per_step=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b98dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a protein WITHOUT guidance\n",
    "generated_protein_no_guided: ESMProtein = model.generate(\n",
    "    input=starting_protein,\n",
    "    config=GenerationConfig(track=\"sequence\", num_steps=len(starting_protein) // 8),\n",
    ")  # type: ignore\n",
    "\n",
    "# Fold\n",
    "generated_protein_no_guided: ESMProtein = model.generate(\n",
    "    input=generated_protein_no_guided,\n",
    "    config=GenerationConfig(track=\"structure\", num_steps=1),\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40723df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pTM Without guidance: {generated_protein_no_guided.ptm:.3f}\")\n",
    "print(f\"pTM With guidance: {generated_protein.ptm:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ecf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x2 grid of viewers (1 row, 2 columns)\n",
    "view = py3Dmol.view(width=1000, height=500, viewergrid=(1, 2))\n",
    "\n",
    "# Convert ESMProtein objects to ProteinChain objects\n",
    "protein_chain1 = generated_protein_no_guided.to_protein_chain()\n",
    "protein_chain2 = generated_protein.to_protein_chain()\n",
    "\n",
    "# Add models to respective panels\n",
    "view.addModel(protein_chain1.to_pdb_string(), \"pdb\", viewer=(0, 0))\n",
    "view.addModel(protein_chain2.to_pdb_string(), \"pdb\", viewer=(0, 1))\n",
    "\n",
    "# Set styles for each protein\n",
    "view.setStyle({}, {\"cartoon\": {\"color\": \"spectrum\"}}, viewer=(0, 0))\n",
    "view.setStyle({}, {\"cartoon\": {\"color\": \"spectrum\"}}, viewer=(0, 1))\n",
    "\n",
    "# Zoom and center the view\n",
    "view.zoomTo()\n",
    "view.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
